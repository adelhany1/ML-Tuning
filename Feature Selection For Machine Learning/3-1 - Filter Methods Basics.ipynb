{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1fdf3b",
   "metadata": {},
   "source": [
    "## 1 - Constant features\n",
    "## 2 - Quasi-constant features\n",
    "## 3 - Duplicated features\n",
    "-  Constant features, all observations in the dataset have the same value for that variable \n",
    "-  Quasi-constant features, where a single value is shared by the great majority of the observations in the dataset (95-99% of observations present the same value)\n",
    "-  Duplicated features, 2 features show same values for all observations. may arise after one hot encoding of categorical variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa9283",
   "metadata": {},
   "source": [
    "## 1 - Constant features\n",
    "\n",
    "- Constant features are those that show the same value, just one value, for all the observations of the dataset. In other words, the same value for all the rows of the dataset. These features provide no information that allows a machine learning model to discriminate or predict a target.\n",
    "\n",
    "- Identifying and removing constant features is an easy first step towards feature selection and more easily interpretable machine learning models.\n",
    "\n",
    "- Here, I will demonstrate how to identify constant features using a dataset that I created for this course. \n",
    "\n",
    "- To identify constant features, we can use the VarianceThreshold from Scikit-learn, or we can code it ourselves. If using the VarianceThreshold, all our variables need to be numerical. If we do it manually however, we can apply the code to both numerical and categorical variables.\n",
    "\n",
    "- will show 2 snippets of code:\n",
    "- 1 where I use the VarianceThreshold \n",
    "- manually coded alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ecc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eea1f6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 301)\n",
      "   var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  var_10  ...  \\\n",
      "0      0      0    0.0   0.00    0.0      0      0      0      0       0  ...   \n",
      "1      0      0    0.0   3.00    0.0      0      0      0      0       0  ...   \n",
      "2      0      0    0.0   5.88    0.0      0      0      0      0       0  ...   \n",
      "3      0      0    0.0  14.10    0.0      0      0      0      0       0  ...   \n",
      "4      0      0    0.0   5.76    0.0      0      0      0      0       0  ...   \n",
      "\n",
      "   var_292  var_293  var_294  var_295  var_296  var_297  var_298  var_299  \\\n",
      "0      0.0        0        0        0        0        1        0      0.0   \n",
      "1      0.0        0        0        0        0        1        0      0.0   \n",
      "2      0.0        0        0        3        0        1        0      0.0   \n",
      "3      0.0        0        0        0        0        1        0      0.0   \n",
      "4      0.0        0        0        0        0        1        0      0.0   \n",
      "\n",
      "      var_300  target  \n",
      "0      0.0000       0  \n",
      "1      0.0000       0  \n",
      "2  67772.7216       0  \n",
      "3      0.0000       0  \n",
      "4      0.0000       0  \n",
      "\n",
      "[5 rows x 301 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset_1.csv')\n",
    "print(data.shape)  # 301 columns without the index, 300 feature and the o/p\n",
    "data['var_297'] = 1\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525260dc",
   "metadata": {},
   "source": [
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fa9af04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 300), (15000, 300))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),  # (X) all columns except the target, drop the target\n",
    "    data['target'],  # (Y) just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65540e",
   "metadata": {},
   "source": [
    "### Using VarianceThreshold from Scikit-learn\n",
    "\n",
    "The VarianceThreshold from sklearn provides a simple baseline approach to feature selection. It removes all features which variance doesn’t meet a certain threshold. \n",
    "\n",
    "By default, it removes all zero-variance features, i.e., features that have the same value in all samples. Same value in the whole column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e75f171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=0)\n",
    "#This feature selection algorithm looks only at the features (X), not the desired outputs (y), and can thus be used for unsupervised learning.\n",
    "# Features with a training-set variance lower than this threshold will be removed. The default is to keep all features with non-zero variance,\n",
    "#   i.e. remove the features that have the same value in all samples. Same value in the whole column\n",
    "\n",
    "sel.fit(X_train)  # fit finds the features with zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "730731ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_support is a boolean vector that indicates which features are retained\n",
    "print(sel.get_support().shape)\n",
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "972727a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we sum over get_support, we get the number of features that are not constant\n",
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c66385d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's print the number of constant feautures\n",
    "constant = X_train.columns[~sel.get_support()]  # ~ get all the Not True (Falses)\n",
    "len(constant)\n",
    "# training data has 34 columns that have the same value in all the column ,, the whole column is ZEROS and var_297 is ones\n",
    "### We can see that 34 columns / variables are constant. This means that 34 variables show the same value, just one value, for all the observations of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e6befcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var_23', 'var_33', 'var_44', 'var_61', 'var_80', 'var_81', 'var_87',\n",
       "       'var_89', 'var_92', 'var_97', 'var_99', 'var_112', 'var_113', 'var_120',\n",
       "       'var_122', 'var_127', 'var_135', 'var_158', 'var_167', 'var_170',\n",
       "       'var_171', 'var_178', 'var_180', 'var_182', 'var_195', 'var_196',\n",
       "       'var_201', 'var_212', 'var_215', 'var_225', 'var_227', 'var_248',\n",
       "       'var_294', 'var_297'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant # the constant variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24be2156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17967    1\n",
       "32391    1\n",
       "9341     1\n",
       "7929     1\n",
       "46544    1\n",
       "        ..\n",
       "21243    1\n",
       "45891    1\n",
       "42613    1\n",
       "43567    1\n",
       "2732     1\n",
       "Name: var_297, Length: 35000, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['var_297']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5925be48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_23 [0]\n",
      "var_33 [0]\n",
      "var_44 [0]\n",
      "var_61 [0]\n",
      "var_80 [0]\n",
      "var_81 [0]\n",
      "var_87 [0]\n",
      "var_89 [0.]\n",
      "var_92 [0]\n",
      "var_97 [0]\n",
      "var_99 [0]\n",
      "var_112 [0]\n",
      "var_113 [0]\n",
      "var_120 [0]\n",
      "var_122 [0]\n",
      "var_127 [0]\n",
      "var_135 [0]\n",
      "var_158 [0]\n",
      "var_167 [0]\n",
      "var_170 [0]\n",
      "var_171 [0]\n",
      "var_178 [0.]\n",
      "var_180 [0.]\n",
      "var_182 [0]\n",
      "var_195 [0]\n",
      "var_196 [0]\n",
      "var_201 [0]\n",
      "var_212 [0]\n",
      "var_215 [0]\n",
      "var_225 [0]\n",
      "var_227 [0.]\n",
      "var_248 [0]\n",
      "var_294 [0]\n",
      "var_297 [1]\n"
     ]
    }
   ],
   "source": [
    "# visualise the values of the constant variables\n",
    "for col in constant:\n",
    "    print(col, X_train[col].unique())  # onl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a28b203",
   "metadata": {},
   "source": [
    "We then use the transform() method of the VarianceThreshold to reduce the training and testing sets to its non-constant features.\n",
    "\n",
    "Note that VarianceThreshold returns a NumPy array without feature names, so we need to capture the names first, and reconstitute the dataframe in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfa7f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-constant feature names (i want to keep)\n",
    "feat_names = X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b1e50a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 300), (15000, 300))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape  # Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5efb4825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 266), (15000, 266))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape  # After\n",
    "# We passed from our original 300 variables, to 266."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ae3e52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5068df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_289</th>\n",
       "      <th>var_290</th>\n",
       "      <th>var_291</th>\n",
       "      <th>var_292</th>\n",
       "      <th>var_293</th>\n",
       "      <th>var_295</th>\n",
       "      <th>var_296</th>\n",
       "      <th>var_298</th>\n",
       "      <th>var_299</th>\n",
       "      <th>var_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  var_10  ...  \\\n",
       "0    0.0    0.0    0.0   2.79    0.0    0.0    0.0    0.0    0.0     0.0  ...   \n",
       "1    0.0    0.0    0.0   2.97    0.0    0.0    0.0    0.0    0.0     0.0  ...   \n",
       "\n",
       "   var_289  var_290  var_291  var_292  var_293  var_295  var_296  var_298  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   var_299  var_300  \n",
       "0      0.0      0.0  \n",
       "1      0.0      0.0  \n",
       "\n",
       "[2 rows x 266 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstitute to dataframe\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=feat_names)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a148f",
   "metadata": {},
   "source": [
    "Reduced Num of features From 300 to 266 by removing the Constant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7f7b5",
   "metadata": {},
   "source": [
    "We see how by removing constant features, we managed to reduced the feature space quite a bit.\n",
    "\n",
    "The VarianceThreshold work with numerical variables. What can we do to find constant categorical variables?\n",
    "\n",
    "One alternative is to encode the categories as numbers and then use the code above. But then you will put effort in pre-processing variables that are not informative.\n",
    "\n",
    "The code below offers a better solution:\n",
    "\n",
    "### Manual Code - works also with categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc2dd6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 300), (15000, 300))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test (again, as we transformed the previous ones)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d26e4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_1      object\n",
       "var_2      object\n",
       "var_3      object\n",
       "var_4      object\n",
       "var_5      object\n",
       "            ...  \n",
       "var_296    object\n",
       "var_297    object\n",
       "var_298    object\n",
       "var_299    object\n",
       "var_300    object\n",
       "Length: 300, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will cast all the numeric features as object,\n",
    "# to simulate that they are categorical\n",
    "\n",
    "X_train = X_train.astype('O')\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d398534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find variables that contain only 1 label/value\n",
    "# we use the nunique() method from pandas, which returns the number\n",
    "# of different values in a variable.\n",
    "\n",
    "constant_features = [\n",
    "    feat for feat in X_train.columns if X_train[feat].nunique() == 1\n",
    "]\n",
    "\n",
    "len(constant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6cd4d82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 266), (15000, 266))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db85aefa",
   "metadata": {},
   "source": [
    "**************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba97fb",
   "metadata": {},
   "source": [
    "********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3da41",
   "metadata": {},
   "source": [
    "*****************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a5390",
   "metadata": {},
   "source": [
    "## 2 -  Quasi-constant features\n",
    "- Same value in almost all observations\n",
    "\n",
    "- Quasi-constant features are those that show the same value for the great majority of the observations of the dataset. In general, these features provide little, if any, information that allows a machine learning model to discriminate or predict a target. But there can be exceptions. So you should be careful when removing these type of features.\n",
    "\n",
    "- Identifying and removing quasi-constant features, is an easy first step towards feature selection and more interpretable machine learning models.\n",
    "\n",
    "- Here, I will demonstrate how to identify quasi-constant features using a dataset that I created for this course. \n",
    "\n",
    "- To identify quasi-constant features, we can use the VarianceThreshold from Scikit-learn, or we can code it ourselves. If we use the VarianceThreshold, all our variables need to be numerical. If we code it manually however, we can apply the code to both numerical and categorical variables.\n",
    "\n",
    "- Will show 2 snippets of code, 1 where I use the VarianceThreshold and 1 manually coded alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29ae8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04a74c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 301)\n",
      "   var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  var_10  ...  \\\n",
      "0      0      0    0.0   0.00    0.0      0      0      0      0       0  ...   \n",
      "1      0      0    0.0   3.00    0.0      0      0      0      0       0  ...   \n",
      "2      0      0    0.0   5.88    0.0      0      0      0      0       0  ...   \n",
      "3      0      0    0.0  14.10    0.0      0      0      0      0       0  ...   \n",
      "4      0      0    0.0   5.76    0.0      0      0      0      0       0  ...   \n",
      "\n",
      "   var_292  var_293  var_294  var_295  var_296  var_297  var_298  var_299  \\\n",
      "0      0.0        0        0        0        0        0        0      0.0   \n",
      "1      0.0        0        0        0        0        0        0      0.0   \n",
      "2      0.0        0        0        3        0        0        0      0.0   \n",
      "3      0.0        0        0        0        0        0        0      0.0   \n",
      "4      0.0        0        0        0        0        0        0      0.0   \n",
      "\n",
      "      var_300  target  \n",
      "0      0.0000       0  \n",
      "1      0.0000       0  \n",
      "2  67772.7216       0  \n",
      "3      0.0000       0  \n",
      "4      0.0000       0  \n",
      "\n",
      "[5 rows x 301 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset_1.csv')\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a27aa741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 300), (15000, 300))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),  # (X) all columns except the target, drop the target\n",
    "    data['target'],  # (Y) just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9f45207c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 266), (15000, 266))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove constant features\n",
    "# remove 34 constant features\n",
    "# Another way , same as VarianceThreshold\n",
    "\n",
    "constant_features = [ feat for feat in X_train.columns if X_train[feat].std() == 0 ]\n",
    "\n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f18865",
   "metadata": {},
   "source": [
    "## Remove quasi-constant features\n",
    "\n",
    "### Using the VarianceThreshold from sklearn\n",
    "\n",
    "The VarianceThreshold from sklearn provides a simple baseline approach to feature selection. It removes all features which variance doesn’t meet a certain threshold. By default, it removes all zero-variance features(threshold=0).\n",
    "\n",
    "Here, we will change the default threshold to remove quasi-constant features, or, I should better say, features with low-variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "56fb02b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0.01)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=0.01)  \n",
    "sel.fit(X_train)  # fit finds the features with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "578528b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1072fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasi_constant = X_train.columns[~sel.get_support()]\n",
    "len(quasi_constant)\n",
    "# 51 columns / variables are almost constant. This means that 51 variables show predominantly one value for the majority of\n",
    "# observations of the training set. Let's explore a few if these variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4f7f1b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var_1', 'var_2', 'var_7', 'var_9', 'var_10', 'var_19', 'var_28',\n",
       "       'var_36', 'var_43', 'var_45', 'var_53', 'var_56', 'var_59', 'var_66',\n",
       "       'var_67', 'var_69', 'var_71', 'var_104', 'var_106', 'var_116',\n",
       "       'var_133', 'var_137', 'var_141', 'var_146', 'var_177', 'var_187',\n",
       "       'var_189', 'var_194', 'var_197', 'var_198', 'var_202', 'var_218',\n",
       "       'var_219', 'var_223', 'var_233', 'var_234', 'var_235', 'var_245',\n",
       "       'var_247', 'var_249', 'var_250', 'var_251', 'var_256', 'var_260',\n",
       "       'var_267', 'var_274', 'var_282', 'var_285', 'var_287', 'var_289',\n",
       "       'var_298'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasi_constant # variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4d68ef16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adel\\AppData\\Local\\Temp\\ipykernel_9208\\2937349211.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train['var_1'].value_counts() / np.float(len(X_train))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.999629\n",
       "3    0.000200\n",
       "6    0.000143\n",
       "9    0.000029\n",
       "Name: var_1, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of observations showing each of the different values of the variable\n",
    "\n",
    "X_train['var_1'].value_counts() / np.float(len(X_train))\n",
    "# more than 99% of the observations show one value, 0. Therefore, this features is fairly constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "85709f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adel\\AppData\\Local\\Temp\\ipykernel_9208\\3649278983.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train['var_2'].value_counts() / np.float(len(X_train))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.999971\n",
       "1    0.000029\n",
       "Name: var_2, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore another one\n",
    "\n",
    "X_train['var_2'].value_counts() / np.float(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "190ecb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.999971\n",
       "1    0.000029\n",
       "Name: var_2, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['var_2'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f909018",
   "metadata": {},
   "source": [
    "We can then remove the quasi-constant features utilizing the transform() method from the VarianceThreshold. and this gives me a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd2c92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c9705cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 215), (15000, 215))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the quasi-constant features\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "# By removing constant and almost constant features, we reduced the feature space from 300 to 215."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b5411dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_12</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_14</th>\n",
       "      <th>var_15</th>\n",
       "      <th>...</th>\n",
       "      <th>var_286</th>\n",
       "      <th>var_288</th>\n",
       "      <th>var_290</th>\n",
       "      <th>var_291</th>\n",
       "      <th>var_292</th>\n",
       "      <th>var_293</th>\n",
       "      <th>var_295</th>\n",
       "      <th>var_296</th>\n",
       "      <th>var_299</th>\n",
       "      <th>var_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_3  var_4  var_5  var_6  var_8  var_11  var_12  var_13  var_14  var_15  \\\n",
       "0    0.0   2.79    0.0    0.0    0.0     0.0     0.0     0.0     0.0     3.0   \n",
       "\n",
       "   ...  var_286  var_288  var_290  var_291  var_292  var_293  var_295  \\\n",
       "0  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   var_296  var_299  var_300  \n",
       "0      0.0      0.0      0.0  \n",
       "\n",
       "[1 rows x 215 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trasnform the array into a dataframe\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=feat_names)\n",
    "X_test = pd.DataFrame(X_test, columns=feat_names)\n",
    "\n",
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99727f16",
   "metadata": {},
   "source": [
    "### Coding it ourselves\n",
    "\n",
    "First, I will separate the dataset into train and test and remove the constant features again. Then, I will provide an alternative method to find out quasi-constant features.\n",
    "\n",
    "This method, as opposed to the VarianceThreshold, can be used for both \n",
    "# **numerical and categorical variables.**\n",
    "Remove Constant and Quasi-constant with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ba1b205d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 266), (15000, 266))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "# remove constant features\n",
    "# using the code from the previous lecture\n",
    "\n",
    "constant_features = [\n",
    "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
    "]\n",
    "\n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3494d61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty list\n",
    "quasi_constant_feat = []\n",
    "\n",
    "# iterate over every feature\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # find the predominant value, that is the value that is shared\n",
    "    # by most observations\n",
    "    predominant = X_train[feature].value_counts(\n",
    "        normalize=True).sort_values(ascending=False).values[0]\n",
    "\n",
    "    # evaluate the predominant feature: do more than 99% of the observations\n",
    "    # show 1 value?\n",
    "    if predominant > 0.998:\n",
    "\n",
    "        # if yes, add the variable to the list\n",
    "        quasi_constant_feat.append(feature)\n",
    "\n",
    "len(quasi_constant_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4ad39070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_1',\n",
       " 'var_2',\n",
       " 'var_3',\n",
       " 'var_6',\n",
       " 'var_7',\n",
       " 'var_9',\n",
       " 'var_10',\n",
       " 'var_11',\n",
       " 'var_12',\n",
       " 'var_14',\n",
       " 'var_16',\n",
       " 'var_20',\n",
       " 'var_24',\n",
       " 'var_28',\n",
       " 'var_32',\n",
       " 'var_34',\n",
       " 'var_36',\n",
       " 'var_39',\n",
       " 'var_40',\n",
       " 'var_42',\n",
       " 'var_43',\n",
       " 'var_45',\n",
       " 'var_48',\n",
       " 'var_53',\n",
       " 'var_56',\n",
       " 'var_59',\n",
       " 'var_60',\n",
       " 'var_65',\n",
       " 'var_66',\n",
       " 'var_67',\n",
       " 'var_69',\n",
       " 'var_71',\n",
       " 'var_72',\n",
       " 'var_73',\n",
       " 'var_77',\n",
       " 'var_78',\n",
       " 'var_90',\n",
       " 'var_95',\n",
       " 'var_98',\n",
       " 'var_102',\n",
       " 'var_104',\n",
       " 'var_106',\n",
       " 'var_111',\n",
       " 'var_115',\n",
       " 'var_116',\n",
       " 'var_124',\n",
       " 'var_125',\n",
       " 'var_126',\n",
       " 'var_129',\n",
       " 'var_130',\n",
       " 'var_133',\n",
       " 'var_136',\n",
       " 'var_138',\n",
       " 'var_141',\n",
       " 'var_142',\n",
       " 'var_146',\n",
       " 'var_149',\n",
       " 'var_150',\n",
       " 'var_151',\n",
       " 'var_153',\n",
       " 'var_159',\n",
       " 'var_183',\n",
       " 'var_184',\n",
       " 'var_187',\n",
       " 'var_189',\n",
       " 'var_197',\n",
       " 'var_202',\n",
       " 'var_204',\n",
       " 'var_210',\n",
       " 'var_211',\n",
       " 'var_216',\n",
       " 'var_217',\n",
       " 'var_219',\n",
       " 'var_221',\n",
       " 'var_223',\n",
       " 'var_224',\n",
       " 'var_228',\n",
       " 'var_233',\n",
       " 'var_234',\n",
       " 'var_235',\n",
       " 'var_236',\n",
       " 'var_237',\n",
       " 'var_239',\n",
       " 'var_243',\n",
       " 'var_245',\n",
       " 'var_246',\n",
       " 'var_247',\n",
       " 'var_249',\n",
       " 'var_251',\n",
       " 'var_254',\n",
       " 'var_257',\n",
       " 'var_260',\n",
       " 'var_263',\n",
       " 'var_264',\n",
       " 'var_265',\n",
       " 'var_267',\n",
       " 'var_274',\n",
       " 'var_280',\n",
       " 'var_282',\n",
       " 'var_283',\n",
       " 'var_285',\n",
       " 'var_286',\n",
       " 'var_287',\n",
       " 'var_289',\n",
       " 'var_290',\n",
       " 'var_291',\n",
       " 'var_298',\n",
       " 'var_299']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our method was a bit more aggressive than VarianceThreshold from sklearn with the threshold that we selected above. \n",
    "#It found 108 features that show predominantly 1 value for the majority of the observations. \n",
    "#Let's see how some of the quasi constant features look like.\n",
    "# print the feature names\n",
    "quasi_constant_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3ca14d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'var_3'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasi_constant_feat[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8900fdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0000         0.999629\n",
       "207901.3365    0.000029\n",
       "15028.0560     0.000029\n",
       "25905.4866     0.000029\n",
       "35685.9459     0.000029\n",
       "3583.3941      0.000029\n",
       "52105.7901     0.000029\n",
       "86718.0000     0.000029\n",
       "861.0900       0.000029\n",
       "2641.0164      0.000029\n",
       "5209.9500      0.000029\n",
       "10281.6000     0.000029\n",
       "12542.3100     0.000029\n",
       "27.3000        0.000029\n",
       "Name: var_3, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['var_3'].value_counts(normalize=True)\n",
    "#The feature shows 0 for more than 99.9% of the observations. But, it also shows a few different values for a very tiny proportion of \n",
    "#the observations. This fact, will increase the feature variance, that is why, this feature is not captured by the VarianceThreshold in\n",
    "#our previous cell. Yet, we can see that it is quasi-constant.\n",
    "#Keep in mind that the thresholds are arbitrary and decided by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "081d748d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 158), (15000, 158))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally, let's drop the quasi-constant features:\n",
    "\n",
    "X_train.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "# We passed from 300 variables to 158."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ecc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

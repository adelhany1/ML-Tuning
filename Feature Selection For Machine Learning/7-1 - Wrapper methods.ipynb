{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0d2e29",
   "metadata": {},
   "source": [
    "# WRAPPER METHODS\n",
    "# 07.1-Step-forward-feature-selection-mlxtend\n",
    "# 07.2-Step-forward-feature-selection-sklearn\n",
    "# 07.3-Step-backward-feature-selection-mlxtend\n",
    "# 07.4-Step-backward-feature-selection-sklearn\n",
    "# 07.5-Exhaustive-feature-selection\n",
    "- Greedy search algorithms, scan all possible combinations of features to determine which one is produces the best ML algorithm\n",
    "- • Extremely computationally expensive\n",
    "- • Often not feasible due to number of features in dataset\n",
    "- • Feature space optimised for a specific algorithm\n",
    "- • Should provide the highest performance\n",
    "- guarantee that best set of features is selected, but computationally expensive\n",
    "- Utilise a specific classifier to select the optimal set of features\n",
    "- Sequential feature selection algorithms: add or remove one feature at the time based on the classifier performance until a feature subset of the desired size k is reached, or any other desired criteria is met\n",
    "- 3 types:\n",
    "- **Step Forward** feature selection algorithms begin from no feature and add one at a time and scan for the performance\n",
    "- **Step backwards** feature selection begins from all the features and removes one feature at a time\n",
    "- **Exhaustive** feature selection tries all possible feature combinations\n",
    "- ...\n",
    "- ...\n",
    "- **STEP FORWARD FEATURE SELECTION**: Evaluates all subsets of 1 feature - Chooses the one that provides best algorithm performance - Evaluates all subsets of 2 features (the first selected and another) - Evaluates algorithm performance - Repeats until criteria is met\n",
    "- **STEP BACKWARD FEATURE SELECTION**: Evaluates all features first - Removes 1 feature and evaluates algorithm performance - Removes second feature and measures performance - Removes third feature and evaluates performance - Repeats until criteria is met\n",
    "- **EXHAUSTIVE FEATURE SELECTION**: Makes all possible feature combinations from 1 to n = total features - And selects the one that provides best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fca147",
   "metadata": {},
   "source": [
    "# Step forward feature selection\n",
    "\n",
    "Step forward feature selection starts by training a machine learning model for each feature in the dataset and selecting, as the starting feature, the one that returns the best performing model according to the evaluation criteria we choose.\n",
    "\n",
    "In the second step, it creates machine learning models for all combinations of the feature selected in the previous step and a second feature. It selects the pair that produces the best performing algorithm.\n",
    "\n",
    "It continues by adding 1 feature at a time to the features that were selected in previous steps, until a stopping criteria is reached.\n",
    "\n",
    "In theory, models with more features perform better. The algorithm will continue adding new features until a certain criteria is met. For example, until the model performance does not increase beyond a certain threshold. Or, as we show in this notebook, until a certain number of features are selected.\n",
    "\n",
    "The model performance metric can be the roc_auc for classification and the r squared for regression, for example, and it is determined by the user. \n",
    "\n",
    "Step forward feature selection is called a greedy procedure because it evaluates many possible single, double, triple, and so on feature combinations. Therefore, it is very computationally expensive and, sometimes, if the feature space is big enough, even unfeasible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a638168",
   "metadata": {},
   "source": [
    "# 07.1-Step-forward-feature-selection-mlxtend\n",
    "There is a special package in Python that implements this type of feature selection: [mlxtend](http://rasbt.github.io/mlxtend/).\n",
    "\n",
    "In the mlxtend implementation of the Step Forward Feature Selection, the original stopping criteria is an arbitrarily set number of features. So the search will finish when we reach the desired number of selected features.\n",
    "\n",
    "This is somewhat arbitrary, we might be selecting a sub-optimal number of features, or likewise, a high number of features. But, by looking at the performance metric returned by the algorithm as it selects the features, we can have a view on whether more features do add value, or not.\n",
    "\n",
    "\n",
    "Here I will use the Step Forward feature selection algorithm from MLXtend in a classification and regression dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22618b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64801a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# within the SFS we indicate:\n",
    "# 1) the algorithm we want to create, in this case RandomForests (note that I use few trees to speed things up)\n",
    "# 2) the stopping criteria: want to select 10 features \n",
    "# 3) wheter to perform step forward or step backward\n",
    "# 4) the evaluation metric: in this case the roc_auc\n",
    "# 5) the cross-validation\n",
    "# this is going to take a while, do not despair\n",
    "sfs = SFS(RandomForestClassifier(n_estimators=10, n_jobs=4, random_state=0), \n",
    "           k_features=10, # the more features we want, the longer it will take to run\n",
    "           forward=True, \n",
    "           floating=False, # see the docs for more details in this parameter\n",
    "           verbose=2, # this indicates how much to print out intermediate steps\n",
    "           scoring='roc_auc', cv=2, )\n",
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb3cf7",
   "metadata": {},
   "source": [
    "# Sklearn is better than mlxtend\n",
    "- Slighlty faster.\n",
    "- Can stop based on model performance.\n",
    "- Parameters we already know.\n",
    "- ...\n",
    "- SO i will use only Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3d4e0",
   "metadata": {},
   "source": [
    "# 07.2-Step-forward-feature-selection-sklearn\n",
    "\n",
    "Scikit-learn provides various stopping criteria to stop the search:\n",
    "\n",
    "* when a certain number of features is reached (like MLXtend) (arbitrary)\n",
    "* if the performance does not increase beyond a certain threshold (ideal but expensive)\n",
    "* selects half of the features (arbitrary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871b5535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41cf1a9",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2399c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 109)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>var_107</th>\n",
       "      <th>var_108</th>\n",
       "      <th>var_109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.53271</td>\n",
       "      <td>3.280834</td>\n",
       "      <td>17.982476</td>\n",
       "      <td>4.404259</td>\n",
       "      <td>2.34991</td>\n",
       "      <td>0.603264</td>\n",
       "      <td>2.784655</td>\n",
       "      <td>0.323146</td>\n",
       "      <td>12.009691</td>\n",
       "      <td>0.139346</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079066</td>\n",
       "      <td>6.748819</td>\n",
       "      <td>2.941445</td>\n",
       "      <td>18.360496</td>\n",
       "      <td>17.726613</td>\n",
       "      <td>7.774031</td>\n",
       "      <td>1.473441</td>\n",
       "      <td>1.973832</td>\n",
       "      <td>0.976806</td>\n",
       "      <td>2.541417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_1     var_2      var_3     var_4    var_5     var_6     var_7  \\\n",
       "0  4.53271  3.280834  17.982476  4.404259  2.34991  0.603264  2.784655   \n",
       "\n",
       "      var_8      var_9    var_10  ...   var_100   var_101   var_102  \\\n",
       "0  0.323146  12.009691  0.139346  ...  2.079066  6.748819  2.941445   \n",
       "\n",
       "     var_103    var_104   var_105   var_106   var_107   var_108   var_109  \n",
       "0  18.360496  17.726613  7.774031  1.473441  1.973832  0.976806  2.541417  \n",
       "\n",
       "[1 rows x 109 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset_2.csv')\n",
    "print(data.shape)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04671cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 108), (15000, 108))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( data.drop(labels=['target'], axis=1), data['target'], test_size=0.3, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb9b63",
   "metadata": {},
   "source": [
    "### Remove Correlated features\n",
    "Step Forward Feature Selection takes a long time to run, so to speed it up we will reduce the feature space by removing correlated features first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b52aa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  36\n"
     ]
    }
   ],
   "source": [
    "# remove correlated features to reduce the feature space\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fde586e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 72), (15000, 72))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove correlated features\n",
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed44bb",
   "metadata": {},
   "source": [
    "### Step Forward Feature Selection\n",
    "\n",
    "We use the [Step Forward Selection class from sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2040eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# within the SFS we indicate:\n",
    "# 1) the algorithm we want to create, in this case RandomForests (note that I use few trees to speed things up)\n",
    "# 2) the stopping criteria: see sklearn documentation for more details\n",
    "# 3) wheter to perform step forward or step backward\n",
    "# 4) the evaluation metric: in this case the roc_auc\n",
    "# 5) the cross-validation\n",
    "# this is going to take a while, do not despair\n",
    "sfs = SFS( estimator=RandomForestClassifier( n_estimators=10, n_jobs=4, random_state=0),\n",
    "    n_features_to_select=10,  # the number of features to retain\n",
    "    tol=None,  # the maximum increase or decrease in the performance metric\n",
    "    direction='forward',  # the direction of the selection procedure\n",
    "    scoring='roc_auc',  # the metric to evaluate\n",
    "    cv=2,  # the cross-validation fold\n",
    "    n_jobs=4,  # for parallelization  \n",
    ")\n",
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ed2734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(cv=2,\n",
       "                          estimator=RandomForestClassifier(n_estimators=10,\n",
       "                                                           n_jobs=4,\n",
       "                                                           random_state=0),\n",
       "                          n_features_to_select=10, n_jobs=4, scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(cv=2,\n",
       "                          estimator=RandomForestClassifier(n_estimators=10,\n",
       "                                                           n_jobs=4,\n",
       "                                                           random_state=0),\n",
       "                          n_features_to_select=10, n_jobs=4, scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10, n_jobs=4, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10, n_jobs=4, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(cv=2,\n",
       "                          estimator=RandomForestClassifier(n_estimators=10,\n",
       "                                                           n_jobs=4,\n",
       "                                                           random_state=0),\n",
       "                          n_features_to_select=10, n_jobs=4, scoring='roc_auc')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107154e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['var_16', 'var_21', 'var_40', 'var_45', 'var_49', 'var_55',\n",
       "       'var_69', 'var_78', 'var_91', 'var_98'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the output above, we can see that after adding the 8th feature, the performance begins to plateau. Adding the 9th and 10th feature did not increase the performance.\n",
    "# If instead of selecting 10 features, we select more as the stopping criteria, we could have a clearer view of the progression of the performance vs number of features.\n",
    "selected_feat = sfs.get_feature_names_out()\n",
    "selected_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c8735",
   "metadata": {},
   "source": [
    "### Compare performance of feature subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f7597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train random forests and evaluate the performance\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca34f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.7129715477516055\n",
      "Test set\n",
      "Random Forests roc-auc: 0.7029127600014389\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of algorithm built using selected features\n",
    "run_randomForests(X_train[selected_feat], X_test[selected_feat], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c37a862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.7119921185820277\n",
      "Test set\n",
      "Random Forests roc-auc: 0.6957598691250635\n"
     ]
    }
   ],
   "source": [
    "# and for comparison, we train random forests using all features (except the correlated ones, which we removed already)\n",
    "run_randomForests(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8681f",
   "metadata": {},
   "source": [
    "in this dataset, with 10 features we obtain a similar performance than that obtained using all variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8c500d",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Let's now repeat the process but in the context of regression. With the house prices dataset from Kaggle, the aim is to predict the continuous target: House Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79fe96f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../houseprice.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f4ad75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 38)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In practice, feature selection should be done after data pre-processing, so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess how deterministic they are of the target\n",
    "# here for simplicity I will use only numerical variables select numerical columns:\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1615e06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 37), (438, 37))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( data.drop(labels=['SalePrice'], axis=1), data['SalePrice'], test_size=0.3, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31129d81",
   "metadata": {},
   "source": [
    "### Remove correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dacf0d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  3\n"
     ]
    }
   ],
   "source": [
    "# find and remove correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85e3cd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 34), (438, 34))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removed correlated features\n",
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1df0ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b7b578",
   "metadata": {},
   "source": [
    "### Step Forward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de0bebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = SFS(estimator = RandomForestRegressor(n_estimators=10, n_jobs=4, random_state=10), \n",
    "    n_features_to_select=10, # the number of features to retain\n",
    "    tol=None, # the maximum increase or decrease in the performance metric\n",
    "    direction='forward', # the direction of the selection procedure\n",
    "    scoring='r2', # the metric to evaluate\n",
    "    cv=2, # the cross-validation fold\n",
    "    n_jobs=4, # for parallelization\n",
    ")\n",
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381a69b",
   "metadata": {},
   "source": [
    "From the logs above, we see that after ~17 features, adding more features does not really improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "800f4b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OverallQual', 'YearBuilt', 'BsmtUnfSF', '1stFlrSF', '2ndFlrSF',\n",
       "       'BsmtFullBath', 'FullBath', 'Fireplaces', 'GarageCars',\n",
       "       'WoodDeckSF'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indices of the selected columns\n",
    "sfs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "275ec2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare performance of feature subsets\n",
    "# function to train random forests and evaluate the performance\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = rf.predict(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(r2_score(y_train, pred)))\n",
    "    print('Test set')\n",
    "    pred = rf.predict(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(r2_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9745faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat = sfs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc53e8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.838674058861943\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8128117376223218\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of algorithm builtusing selected features\n",
    "run_randomForests(X_train[selected_feat], X_test[selected_feat], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ed7c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8699152317492538\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8190809813112794\n"
     ]
    }
   ],
   "source": [
    "# and for comparison, we train random forests using\n",
    "# all features (except the correlated ones, which we removed already)\n",
    "run_randomForests(X_train, X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "712602a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that the algorithm with 20 features performs as well as that with 24 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e3075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
